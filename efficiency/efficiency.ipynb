{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mambular.base_models.mambular import Mambular\n",
    "from mambular.base_models.tabtransformer import TabTransformer\n",
    "from mambular.base_models.ft_transformer import FTTransformer\n",
    "from mambular.base_models.mlp import MLP\n",
    "from mambular.base_models.mambatab import MambaTab\n",
    "from mambular.base_models.resnet import ResNet\n",
    "from mambular.base_models.mambattn import MambAttention\n",
    "from mambular.base_models.tabularnn import TabulaRNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import ProfileKwargs\n",
    "import re\n",
    "from torch.profiler import profile, ProfilerActivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features (10-100) GPU efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\"Model\", \"Num Features\", \"Total CUDA Memory (MB)\", \"Total CUDA Time (ms)\"]\n",
    ")\n",
    "\n",
    "# Set up the profiler with memory profiling enabled\n",
    "profile_kwargs = ProfileKwargs(\n",
    "    activities=[\"cpu\", \"cuda\"], profile_memory=True, record_shapes=True\n",
    ")\n",
    "accelerator = Accelerator(cpu=False, kwargs_handlers=[profile_kwargs])\n",
    "\n",
    "# Loop over different numbers of features\n",
    "for n_features in range(10, 100, 10): \n",
    "    # Updated dictionaries for feature info\n",
    "    cat_feature_info = {\n",
    "        f\"cat_feature_{i}\": 10 for i in range(int(n_features/2))\n",
    "    }  # 10 categories: 0 to 9\n",
    "    num_feature_info = {\n",
    "        f\"num_feature_{i}\": 64 for i in range(int(n_features/2))\n",
    "    }  # 128-dimensional numerical features\n",
    "\n",
    "    # Create random numerical and categorical features, and move to CUDA\n",
    "    num_features = [torch.randn(32, 64).cuda() for _ in range(int(n_features/2))]\n",
    "    cat_features = [\n",
    "        torch.randint(low=0, high=10, size=(32, 1)).cuda() for _ in range(int(n_features/2))\n",
    "    ]\n",
    "\n",
    "    models = [\n",
    "        Mambular(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "        ).cuda(),\n",
    "        FTTransformer(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "            n_layers=5,\n",
    "        ).cuda(),\n",
    "        TabulaRNN(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            d_model=128,\n",
    "            dim_feedforward=256,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            n_layers=4,\n",
    "        ).cuda(),\n",
    "        MLP(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            layer_sizes=[512, 256, 128, 32],\n",
    "        ).cuda(),\n",
    "        ResNet(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            layer_sizes=[512, 256, 16],\n",
    "        ).cuda(),\n",
    "        MambAttention(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_state=172,\n",
    "        ).cuda(),\n",
    "    ]\n",
    "\n",
    "    # Iterate over the models\n",
    "    for model in models:\n",
    "        # Prepare the model using the accelerator\n",
    "        #model = accelerator.prepare(model)\n",
    "\n",
    "        # Profiling the model\n",
    "        with profile(profile_memory=True, record_shapes=True) as prof:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(num_features, cat_features)\n",
    "\n",
    "        # Extract key metrics from profiler\n",
    "        key_averages = prof.key_averages()\n",
    "        key_avg_output = str(key_averages.total_average())\n",
    "\n",
    "\n",
    "\n",
    "        # Extract cuda_memory_usage\n",
    "        cuda_memory_match = re.search(r'cuda_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cuda_memory = int(cuda_memory_match.group(1)) / (1024 ** 2) if cuda_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract cpu_memory_usage\n",
    "        cpu_memory_match = re.search(r'cpu_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cpu_memory = int(cpu_memory_match.group(1)) / (1024 ** 2) if cpu_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract self_cpu_time (convert from ms)\n",
    "        cpu_time_match = re.search(r'self_cpu_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cpu_time = float(cpu_time_match.group(1)) if cpu_time_match else 0.0  # CPU time in ms\n",
    "\n",
    "        # Extract self_cuda_time (convert from ms)\n",
    "        cuda_time_match = re.search(r'self_cuda_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cuda_time = float(cuda_time_match.group(1)) if cuda_time_match else 0.0  # CUDA time in ms\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": model.__class__.__name__,\n",
    "            \"Num Features\": n_features,\n",
    "            \"Total CPU Time (ms)\": total_cpu_time,\n",
    "            \"Total CUDA Time (ms)\": total_cuda_time,\n",
    "            \"Total CPU Memory (MB)\": total_cpu_memory,\n",
    "            \"Total CUDA Memory (MB)\": total_cuda_memory,\n",
    "        }\n",
    "\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Display the profiling results\n",
    "print(df_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features (0-1000) GPU Efficiency. Batch Size is adapted to 8 to avoid crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mambular.base_models.mambular import Mambular\n",
    "from mambular.base_models.tabtransformer import TabTransformer\n",
    "from mambular.base_models.ft_transformer import FTTransformer\n",
    "from mambular.base_models.mlp import MLP\n",
    "from mambular.base_models.resnet import ResNet\n",
    "from mambular.base_models.mambattn import MambAttention\n",
    "from mambular.base_models.tabularnn import TabulaRNN\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import ProfileKwargs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "# Parse the string to extract values using regex\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Initialize models with updated feature info\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\"Model\", \"Num Features\", \"Total CUDA Memory (MB)\", \"Total CUDA Time (ms)\"]\n",
    ")\n",
    "\n",
    "# Set up the profiler with memory profiling enabled\n",
    "profile_kwargs = ProfileKwargs(\n",
    "    activities=[\"cpu\", \"cuda\"], profile_memory=True, record_shapes=True\n",
    ")\n",
    "accelerator = Accelerator(cpu=False, kwargs_handlers=[profile_kwargs])\n",
    "\n",
    "# Loop over different numbers of features\n",
    "for n_features in range(10, 1000, 100):\n",
    "\n",
    "    # Updated dictionaries for feature info\n",
    "    cat_feature_info = {\n",
    "        f\"cat_feature_{i}\": 10 for i in range(int(n_features/2))\n",
    "    }  # 10 categories: 0 to 9\n",
    "    num_feature_info = {\n",
    "        f\"num_feature_{i}\": 64 for i in range(int(n_features/2))\n",
    "    }  # 128-dimensional numerical features\n",
    "\n",
    "    # Create random numerical and categorical features, and move to CUDA\n",
    "    num_features = [torch.randn(8, 64).cuda() for _ in range(int(n_features/2))]\n",
    "    cat_features = [\n",
    "        torch.randint(low=0, high=10, size=(8, 1)).cuda() for _ in range(int(n_features/2))\n",
    "    ]\n",
    "\n",
    "    models = [\n",
    "        Mambular(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "        ).cuda(),\n",
    "        FTTransformer(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "            n_layers=5,\n",
    "        ).cuda(),\n",
    "        TabulaRNN(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            d_model=128,\n",
    "            dim_feedforward=256,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            n_layers=4,\n",
    "        ).cuda(),\n",
    "        MLP(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            layer_sizes=[512, 256, 128, 32],\n",
    "        ).cuda(),\n",
    "        ResNet(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            layer_sizes=[512, 256, 16],\n",
    "        ).cuda(),\n",
    "        MambAttention(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_state=172,\n",
    "        ).cuda(),\n",
    "    ]\n",
    "\n",
    "    # Iterate over the models\n",
    "    for model in models:\n",
    "        # Prepare the model using the accelerator\n",
    "        #model = accelerator.prepare(model)\n",
    "\n",
    "        # Profiling the model\n",
    "        with profile(profile_memory=True, record_shapes=True) as prof:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(num_features, cat_features)\n",
    "\n",
    "        # Extract key metrics from profiler\n",
    "        key_averages = prof.key_averages()\n",
    "        key_avg_output = str(key_averages.total_average())\n",
    "\n",
    "\n",
    "\n",
    "        # Extract cuda_memory_usage\n",
    "        cuda_memory_match = re.search(r'cuda_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cuda_memory = int(cuda_memory_match.group(1)) / (1024 ** 2) if cuda_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract cpu_memory_usage\n",
    "        cpu_memory_match = re.search(r'cpu_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cpu_memory = int(cpu_memory_match.group(1)) / (1024 ** 2) if cpu_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract self_cpu_time (convert from ms)\n",
    "        cpu_time_match = re.search(r'self_cpu_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cpu_time = float(cpu_time_match.group(1)) if cpu_time_match else 0.0  # CPU time in ms\n",
    "\n",
    "        # Extract self_cuda_time (convert from ms)\n",
    "        cuda_time_match = re.search(r'self_cuda_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cuda_time = float(cuda_time_match.group(1)) if cuda_time_match else 0.0  # CUDA time in ms\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": model.__class__.__name__,\n",
    "            \"Num Features\": n_features,\n",
    "            \"Total CPU Time (ms)\": total_cpu_time,\n",
    "            \"Total CUDA Time (ms)\": total_cuda_time,\n",
    "            \"Total CPU Memory (MB)\": total_cpu_memory,\n",
    "            \"Total CUDA Memory (MB)\": total_cuda_memory,\n",
    "        }\n",
    "\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Display the profiling results\n",
    "print(df_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU vs Embedding dimension -> Batch size of 32, fixed feature number of 12 to simulate average tabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mambular.base_models.mambular import Mambular\n",
    "from mambular.base_models.tabtransformer import TabTransformer\n",
    "from mambular.base_models.ft_transformer import FTTransformer\n",
    "from mambular.base_models.mlp import MLP\n",
    "from mambular.base_models.resnet import ResNet\n",
    "from mambular.base_models.mambattn import MambAttention\n",
    "from mambular.base_models.tabularnn import TabulaRNN\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import ProfileKwargs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "# Parse the string to extract values using regex\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Initialize models with updated feature info\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "df_results = pd.DataFrame(\n",
    "    columns=[\"Model\", \"Num Layers\", \"Total CUDA Memory (MB)\", \"Total CUDA Time (ms)\"]\n",
    ")\n",
    "\n",
    "# Set up the profiler with memory profiling enabled\n",
    "profile_kwargs = ProfileKwargs(\n",
    "    activities=[\"cpu\", \"cuda\"], profile_memory=True, record_shapes=True\n",
    ")\n",
    "accelerator = Accelerator(cpu=False, kwargs_handlers=[profile_kwargs])\n",
    "n_features=12\n",
    "\n",
    "# Loop over different numbers of features\n",
    "for n_layers in range(4, 24):\n",
    "\n",
    "    # Updated dictionaries for feature info\n",
    "    cat_feature_info = {\n",
    "        f\"cat_feature_{i}\": 10 for i in range(int(n_features/2))\n",
    "    }  # 10 categories: 0 to 9\n",
    "    num_feature_info = {\n",
    "        f\"num_feature_{i}\": 64 for i in range(int(n_features/2))\n",
    "    }  # 128-dimensional numerical features\n",
    "\n",
    "    # Create random numerical and categorical features, and move to CUDA\n",
    "    num_features = [torch.randn(32, 64).cuda() for _ in range(int(n_features/2))]\n",
    "    cat_features = [\n",
    "        torch.randint(low=0, high=10, size=(32, 1)).cuda() for _ in range(int(n_features/2))\n",
    "    ]\n",
    "\n",
    "    models = [\n",
    "        Mambular(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "            n_layers=n_layers\n",
    "        ).cuda(),\n",
    "        FTTransformer(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            d_model=64,\n",
    "            n_layers=n_layers\n",
    "        ).cuda(),\n",
    "        TabulaRNN(\n",
    "            num_feature_info=num_feature_info,\n",
    "            cat_feature_info=cat_feature_info,\n",
    "            d_model=128,\n",
    "            dim_feedforward=256,\n",
    "            numerical_preprocessing=\"ple\",\n",
    "            n_bins=64,\n",
    "            n_layers=n_layers\n",
    "        ).cuda(),\n",
    "    ]\n",
    "\n",
    "    # Iterate over the models\n",
    "    for model in models:\n",
    "        # Prepare the model using the accelerator\n",
    "        #model = accelerator.prepare(model)\n",
    "\n",
    "        # Profiling the model\n",
    "        with profile(profile_memory=True, record_shapes=True) as prof:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(num_features, cat_features)\n",
    "\n",
    "        # Extract key metrics from profiler\n",
    "        key_averages = prof.key_averages()\n",
    "        key_avg_output = str(key_averages.total_average())\n",
    "\n",
    "\n",
    "\n",
    "        # Extract cuda_memory_usage\n",
    "        cuda_memory_match = re.search(r'cuda_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cuda_memory = int(cuda_memory_match.group(1)) / (1024 ** 2) if cuda_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract cpu_memory_usage\n",
    "        cpu_memory_match = re.search(r'cpu_memory_usage=(\\d+)', key_avg_output)\n",
    "        total_cpu_memory = int(cpu_memory_match.group(1)) / (1024 ** 2) if cpu_memory_match else 0.0  # Convert to MB\n",
    "\n",
    "        # Extract self_cpu_time (convert from ms)\n",
    "        cpu_time_match = re.search(r'self_cpu_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cpu_time = float(cpu_time_match.group(1)) if cpu_time_match else 0.0  # CPU time in ms\n",
    "\n",
    "        # Extract self_cuda_time (convert from ms)\n",
    "        cuda_time_match = re.search(r'self_cuda_time=([\\d.]+)ms', key_avg_output)\n",
    "        total_cuda_time = float(cuda_time_match.group(1)) if cuda_time_match else 0.0  # CUDA time in ms\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": model.__class__.__name__,\n",
    "            \"Num Layers\": int(n_layers),\n",
    "            \"Total CPU Time (ms)\": total_cpu_time,\n",
    "            \"Total CUDA Time (ms)\": total_cuda_time,\n",
    "            \"Total CPU Memory (MB)\": total_cpu_memory,\n",
    "            \"Total CUDA Memory (MB)\": total_cuda_memory,\n",
    "        }\n",
    "\n",
    "        # Append the new row to the DataFrame using pd.concat\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Display the profiling results\n",
    "print(df_results.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
